{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CueSKGS3K_QP"
   },
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rx-cxHxTKIxK"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense , Conv2D , MaxPooling2D , Dropout , BatchNormalization , Flatten , MaxPool2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aYeeqmT0M69o"
   },
   "source": [
    "### Build the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GFLrzWT7MOZp"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu' , input_shape = (64,64,3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
    "\n",
    "model.add(Conv2D(64 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.1))\n",
    "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
    "\n",
    "model.add(Conv2D(64 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
    "\n",
    "model.add(Conv2D(128 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
    "model.add(Conv2D(256 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(units = 128 , activation = 'relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units = 1 , activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mEc46NFtOlk8",
    "outputId": "1c3dc2d0-7c87-4eb0-d53a-ddbe339bd1bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_24 (Conv2D)          (None, 64, 64, 32)        896       \n",
      "                                                                 \n",
      " batch_normalization_20 (Bat  (None, 64, 64, 32)       128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_19 (MaxPoolin  (None, 32, 32, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_25 (Conv2D)          (None, 32, 32, 64)        18496     \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " batch_normalization_21 (Bat  (None, 32, 32, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_20 (MaxPoolin  (None, 16, 16, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_26 (Conv2D)          (None, 16, 16, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_22 (Bat  (None, 16, 16, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_21 (MaxPoolin  (None, 8, 8, 64)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_27 (Conv2D)          (None, 8, 8, 128)         73856     \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " batch_normalization_23 (Bat  (None, 8, 8, 128)        512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_22 (MaxPoolin  (None, 4, 4, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_28 (Conv2D)          (None, 4, 4, 256)         295168    \n",
      "                                                                 \n",
      " dropout_20 (Dropout)        (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " batch_normalization_24 (Bat  (None, 4, 4, 256)        1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_23 (MaxPoolin  (None, 2, 2, 256)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 128)               131200    \n",
      "                                                                 \n",
      " dropout_21 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 558,849\n",
      "Trainable params: 557,761\n",
      "Non-trainable params: 1,088\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KusxLSp1O1lO"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import  Adam\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "svvmFoVIO_y0"
   },
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U4UPwLpiL3_b"
   },
   "outputs": [],
   "source": [
    "# Paths\n",
    "train_dir = '/dataset/train'\n",
    "test_dir = '/dataset/test'\n",
    "val_dir = '/dataset/val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xI9NMc64K99Y",
    "outputId": "c635b3f9-3f0e-4576-b111-9cac03418be0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5216 images belonging to 2 classes.\n",
      "Found 68 images belonging to 2 classes.\n",
      "Found 16 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(64, 64),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size=(64, 64),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "val_generator = test_datagen.flow_from_directory(\n",
    "        val_dir,\n",
    "        target_size=(64, 64),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uDBe-QmhPJP0"
   },
   "source": [
    "### Traning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "awlIBL_kUsPN",
    "outputId": "356c7f40-0968-4f76-c7e4-25bd8331a6ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.1805 - accuracy: 0.9291WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 624 batches). You may need to use the repeat() function when building your dataset.\n",
      "163/163 [==============================] - 79s 483ms/step - loss: 0.1805 - accuracy: 0.9291 - val_loss: 6.9689 - val_accuracy: 0.5000\n",
      "Epoch 2/5\n",
      "163/163 [==============================] - 80s 490ms/step - loss: 0.1634 - accuracy: 0.9419\n",
      "Epoch 3/5\n",
      "163/163 [==============================] - 81s 498ms/step - loss: 0.1608 - accuracy: 0.9387\n",
      "Epoch 4/5\n",
      "163/163 [==============================] - 79s 484ms/step - loss: 0.1459 - accuracy: 0.9465\n",
      "Epoch 5/5\n",
      "163/163 [==============================] - 81s 498ms/step - loss: 0.1318 - accuracy: 0.9509\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator,\n",
    "                         steps_per_epoch = 163,\n",
    "                         epochs = 5,\n",
    "                         validation_data = val_generator,\n",
    "                         validation_steps = 624)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9MbWtLfaMHQF",
    "outputId": "86b474a3-e1a5-4b19-c771-d08ff898457b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  3/624 [..............................] - ETA: 5:09 - loss: 0.2747 - accuracy: 0.8529WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 624 batches). You may need to use the repeat() function when building your dataset.\n",
      "624/624 [==============================] - 2s 2ms/step - loss: 0.2747 - accuracy: 0.8529\n",
      "163/163 [==============================] - 81s 495ms/step - loss: 0.1215 - accuracy: 0.9571\n",
      "The testing accuracy is : 85.29411554336548 %\n",
      "The training accuracy is : 95.70552110671997 %\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = model.evaluate(test_generator,steps=624)\n",
    "train_accuracy = model.evaluate(train_generator,steps=163)\n",
    "print('The testing accuracy is :',test_accuracy[1]*100, '%')\n",
    "print('The training accuracy is :',train_accuracy[1]*100, '%')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Pneumonia_Prediction.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
